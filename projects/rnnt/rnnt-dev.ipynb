{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-04-04 12:23:56--  https://raw.githubusercontent.com/lorenlugosch/infer_missing_vowels/master/data/train/war_and_peace.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3196229 (3.0M) [text/plain]\n",
      "Saving to: ‘war_and_peace.txt’\n",
      "\n",
      "war_and_peace.txt   100%[===================>]   3.05M  5.66MB/s    in 0.5s    \n",
      "\n",
      "2023-04-04 12:23:57 (5.66 MB/s) - ‘war_and_peace.txt’ saved [3196229/3196229]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get training data.\n",
    "!wget https://raw.githubusercontent.com/lorenlugosch/infer_missing_vowels/master/data/train/war_and_peace.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.16 (default, Dec  7 2022, 01:27:54) \n",
      "Type 'copyright', 'credits' or 'license' for more information\n",
      "IPython 8.6.0 -- An enhanced Interactive Python. Type '?' for help.\n",
      "\n",
      "Out[1]: \n",
      "tensor([[[-2.8397e-01, -9.0466e-01, -1.3844e-01,  ...,  1.2482e-01,\n",
      "          -1.6752e+00, -9.1686e-01],\n",
      "         [ 2.2266e-01,  3.1771e-01, -4.3722e-01,  ..., -1.5623e-01,\n",
      "          -7.4187e-01,  8.8158e-02],\n",
      "         [ 1.7360e-01, -4.5565e-01, -1.2003e-01,  ...,  2.5013e-01,\n",
      "           7.7036e-01,  3.0499e-01],\n",
      "         ...,\n",
      "         [ 5.8290e-01, -1.1187e-01,  9.9949e-01,  ...,  4.4725e-01,\n",
      "          -9.8940e-01,  1.5680e-01],\n",
      "         [-6.3546e-01, -2.5261e-01,  1.5095e+00,  ..., -1.8255e+00,\n",
      "           8.3142e-01, -2.1155e-01],\n",
      "         [-4.5400e-01, -8.5388e-01, -2.2525e-01,  ..., -2.6675e-01,\n",
      "          -3.1050e-01,  1.5431e+00]],\n",
      "\n",
      "        [[-1.3305e+00, -5.4794e-01,  9.7787e-02,  ...,  1.3837e+00,\n",
      "          -1.2150e+00,  1.0774e+00],\n",
      "         [-1.1048e+00, -5.8884e-01, -9.2180e-01,  ..., -3.7802e-01,\n",
      "          -1.0398e+00,  2.8599e-01],\n",
      "         [ 1.1724e+00, -6.6188e-01, -1.7217e+00,  ..., -1.5681e-01,\n",
      "           1.9260e+00, -1.5678e+00],\n",
      "         ...,\n",
      "         [ 4.0248e-01,  1.4016e+00,  7.3763e-01,  ..., -1.2188e-01,\n",
      "           2.2733e+00, -1.2051e+00],\n",
      "         [-1.1139e+00, -1.6396e-02,  1.7231e-01,  ...,  4.4195e-02,\n",
      "          -2.6955e-01,  4.8984e-01],\n",
      "         [ 8.5811e-02,  9.3611e-01,  4.7214e-01,  ...,  9.0727e-02,\n",
      "           2.3802e-01, -1.8443e-01]],\n",
      "\n",
      "        [[ 7.9655e-01, -6.7708e-01, -8.8657e-01,  ..., -1.0126e+00,\n",
      "           7.3982e-01, -1.2004e-02],\n",
      "         [-7.1454e-01, -5.0905e-01, -1.7092e+00,  ...,  6.4784e-01,\n",
      "          -1.1131e+00,  1.8398e+00],\n",
      "         [ 1.0822e+00, -6.4199e-01,  3.2014e-01,  ...,  1.5389e+00,\n",
      "           1.6660e+00,  2.1579e-01],\n",
      "         ...,\n",
      "         [-5.8693e-01,  8.1112e-01,  1.9583e-01,  ...,  2.4115e+00,\n",
      "           1.0046e-01,  2.0634e+00],\n",
      "         [ 1.7776e-01,  1.3172e-01,  5.4462e-01,  ...,  9.4418e-01,\n",
      "          -1.6172e-01,  1.0936e+00],\n",
      "         [-1.2748e-01, -1.2046e-01, -8.7465e-01,  ..., -1.0226e+00,\n",
      "           1.0695e+00,  1.0226e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.8021e-01,  5.0374e-01,  6.8998e-01,  ...,  7.2421e-01,\n",
      "          -2.4987e-01,  8.5678e-03],\n",
      "         [ 1.2306e+00,  1.2033e+00, -1.3029e+00,  ...,  8.2696e-01,\n",
      "          -1.5381e+00,  4.0830e-01],\n",
      "         [-1.0050e+00, -7.3012e-01, -8.1839e-01,  ...,  9.6352e-03,\n",
      "          -1.0252e+00,  8.2353e-01],\n",
      "         ...,\n",
      "         [ 1.6863e-01,  1.0181e+00, -1.1325e+00,  ..., -1.1086e+00,\n",
      "           8.2860e-01, -6.3982e-01],\n",
      "         [-8.0951e-01,  2.3925e+00,  2.2013e+00,  ...,  4.9009e-01,\n",
      "          -5.7278e-01,  1.8469e+00],\n",
      "         [-2.0148e+00,  2.2486e+00,  9.5198e-02,  ...,  2.8441e-01,\n",
      "           2.8004e-02,  2.5556e-01]],\n",
      "\n",
      "        [[-1.8506e-01, -9.1496e-01,  8.4786e-01,  ...,  1.9736e-01,\n",
      "          -5.1510e-02, -1.2261e+00],\n",
      "         [-6.5036e-01, -1.7090e+00, -1.3245e+00,  ..., -1.5806e+00,\n",
      "          -1.9220e-01, -5.6760e-01],\n",
      "         [-9.1580e-01,  1.7215e+00,  1.5054e+00,  ...,  1.4016e+00,\n",
      "           3.7174e-01, -1.3900e+00],\n",
      "         ...,\n",
      "         [-9.5933e-02, -1.2808e+00,  8.7777e-01,  ..., -1.4476e-01,\n",
      "          -1.0782e+00, -1.9104e-01],\n",
      "         [-9.6074e-01, -5.4601e-02, -1.8219e+00,  ..., -6.1499e-01,\n",
      "          -1.8738e-01,  1.4673e-03],\n",
      "         [ 1.2800e+00,  1.9621e-01,  3.7138e-01,  ..., -7.3534e-01,\n",
      "           1.0489e-01,  6.5999e-02]],\n",
      "\n",
      "        [[-6.5178e-01,  5.1073e-01,  2.0688e-01,  ...,  5.3415e-01,\n",
      "           9.0743e-01, -6.3991e-01],\n",
      "         [ 5.3268e-03,  1.6974e+00,  1.8342e-01,  ..., -1.7274e+00,\n",
      "           1.0231e+00, -1.6223e+00],\n",
      "         [-6.4404e-01,  1.1097e+00, -4.8251e-01,  ...,  9.5532e-02,\n",
      "          -1.1635e+00,  3.0486e-01],\n",
      "         ...,\n",
      "         [-1.0626e+00, -1.0038e+00,  6.0242e-01,  ...,  5.0018e-01,\n",
      "          -3.4396e-01, -3.2430e-01],\n",
      "         [ 2.2075e+00,  2.6352e+00, -1.4380e+00,  ..., -3.9325e-01,\n",
      "          -1.0598e+00,  2.0918e-02],\n",
      "         [-1.4709e+00,  9.8511e-03, -1.2793e-01,  ...,  1.3403e-01,\n",
      "           6.0005e-01,  1.8346e+00]]])\n",
      "\n",
      "Out[2]: torch.Size([10, 32, 512])\n",
      "\n",
      "\n",
      "Out[4]: torch.Size([10, 32, 512])\n",
      "\n",
      "Out[5]: \n",
      "tensor([[[-4.2996e-01, -6.6395e-01, -5.6291e-01,  ..., -6.3248e-01,\n",
      "          -3.8209e-01,  1.3616e+00],\n",
      "         [ 1.1035e+00,  1.2935e-01, -1.5715e+00,  ...,  6.1209e-01,\n",
      "          -5.5362e-01,  1.6940e+00],\n",
      "         [ 5.3832e-01, -4.3155e-01, -5.1309e-01,  ...,  7.1894e-01,\n",
      "          -8.4931e-01,  2.2582e+00],\n",
      "         ...,\n",
      "         [ 4.9000e-01, -2.6030e-01,  8.6016e-02,  ...,  6.8583e-01,\n",
      "          -7.5120e-01,  3.8664e-01],\n",
      "         [-7.2158e-01, -5.0394e-01, -9.9631e-01,  ..., -2.2141e+00,\n",
      "           1.8960e-01,  5.1635e-01],\n",
      "         [ 4.8603e-01,  1.8350e+00, -9.9575e-01,  ..., -1.1940e+00,\n",
      "          -1.5286e-01,  2.0909e+00]],\n",
      "\n",
      "        [[-1.0306e+00, -3.1519e-01, -8.1951e-01,  ..., -6.4983e-01,\n",
      "          -1.8034e+00,  1.5362e+00],\n",
      "         [ 9.7554e-01, -6.5661e-02, -1.2217e+00,  ...,  8.3528e-01,\n",
      "          -1.8009e-01,  1.9101e-01],\n",
      "         [ 2.3767e-01, -7.8619e-01, -1.2183e+00,  ...,  3.1114e-01,\n",
      "           1.3503e+00,  7.1738e-01],\n",
      "         ...,\n",
      "         [ 7.9582e-01,  8.1973e-01,  1.8260e-01,  ...,  1.7781e-01,\n",
      "           1.5901e+00,  6.0841e-01],\n",
      "         [-7.6790e-01, -7.6490e-01, -1.4283e+00,  ...,  1.0185e-03,\n",
      "           1.4144e+00,  5.6985e-01],\n",
      "         [-1.5284e-01,  1.2236e+00, -1.7346e-01,  ..., -6.0923e-01,\n",
      "          -3.0530e-01,  4.8496e-01]],\n",
      "\n",
      "        [[-1.4611e-01,  4.0566e-01, -5.8075e-02,  ..., -2.5044e-03,\n",
      "           3.6539e-02,  1.4890e+00],\n",
      "         [ 5.9053e-01, -3.9685e-01, -1.5119e+00,  ...,  6.0210e-01,\n",
      "           5.2515e-01,  1.5717e+00],\n",
      "         [ 6.5251e-01, -3.6712e-02,  1.8837e-01,  ...,  1.6072e+00,\n",
      "          -3.2555e-02,  1.9387e+00],\n",
      "         ...,\n",
      "         [ 3.9276e-01, -2.3564e-01, -4.6145e-01,  ...,  8.6933e-01,\n",
      "           2.8654e-01,  1.2605e+00],\n",
      "         [-8.0506e-01, -1.0482e+00, -1.0937e+00,  ...,  7.9488e-02,\n",
      "          -6.1364e-01,  1.2452e+00],\n",
      "         [-1.1156e+00,  1.3449e+00, -1.2505e+00,  ..., -1.6188e+00,\n",
      "          -4.3334e-01,  2.3516e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.1695e+00,  1.0296e+00, -1.0115e+00,  ..., -1.7486e-01,\n",
      "          -2.4619e-01,  1.0200e+00],\n",
      "         [ 1.4781e+00,  6.4995e-01, -1.2021e+00,  ...,  1.0398e+00,\n",
      "          -1.2847e-01,  2.3583e+00],\n",
      "         [-8.1993e-02, -7.6244e-01, -5.4691e-01,  ...,  1.1448e+00,\n",
      "          -9.7542e-01,  1.3410e+00],\n",
      "         ...,\n",
      "         [ 1.3519e+00,  7.9349e-01, -1.4820e+00,  ..., -7.1475e-01,\n",
      "           1.0259e+00,  1.1418e+00],\n",
      "         [-9.3887e-01,  4.4484e-01, -6.2194e-01,  ..., -8.0365e-01,\n",
      "          -3.1608e-02,  1.7122e+00],\n",
      "         [-4.7337e-01,  1.1742e+00, -9.7445e-01,  ..., -1.3820e+00,\n",
      "          -1.1319e+00,  1.0410e+00]],\n",
      "\n",
      "        [[-1.3134e+00,  2.5348e-01,  1.0965e-01,  ..., -1.1075e+00,\n",
      "           2.7890e-01,  1.1814e+00],\n",
      "         [ 3.0441e-01,  6.7579e-02, -1.6119e+00,  ...,  3.4660e-01,\n",
      "          -3.4020e-01,  1.1047e+00],\n",
      "         [ 4.3300e-01,  1.4056e-01,  8.3783e-01,  ...,  9.2070e-01,\n",
      "           2.6033e-01,  9.2309e-01],\n",
      "         ...,\n",
      "         [-3.9279e-01, -2.9120e-01, -8.2164e-01,  ..., -2.1749e-01,\n",
      "           1.9268e-01,  4.3352e-01],\n",
      "         [ 2.3971e-01, -1.9689e-01, -2.2138e+00,  ..., -1.0125e+00,\n",
      "           3.8356e-01, -3.1531e-01],\n",
      "         [-4.4232e-01,  2.2692e-01,  1.3425e-01,  ..., -1.0887e+00,\n",
      "          -3.8883e-01,  7.5739e-01]],\n",
      "\n",
      "        [[-4.4934e-01,  7.3045e-01, -2.7386e-01,  ..., -8.4956e-01,\n",
      "           2.0325e-01,  1.0769e+00],\n",
      "         [ 7.8229e-01,  1.6667e+00, -5.9214e-01,  ..., -5.0984e-01,\n",
      "           3.7555e-01,  2.1026e-01],\n",
      "         [-2.1668e-01, -4.1524e-01, -3.0264e-01,  ...,  1.4908e+00,\n",
      "          -4.3707e-01,  1.4871e+00],\n",
      "         ...,\n",
      "         [ 1.8236e-01, -9.2046e-01, -7.5217e-01,  ...,  4.9343e-01,\n",
      "           2.3986e-01,  1.4570e+00],\n",
      "         [ 1.0307e+00, -1.4725e-01, -1.9017e+00,  ..., -8.1552e-01,\n",
      "          -3.3669e-01,  1.3347e+00],\n",
      "         [-5.0066e-01,  1.1713e+00, -7.5436e-01,  ..., -4.3527e-01,\n",
      "          -2.9950e-01,  1.0115e+00]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "\n",
      "\n",
      "Out[7]: \n",
      "tensor([[[-0.3155,  0.1059, -0.0000,  ...,  1.2498, -1.8613,  0.0924],\n",
      "         [ 0.2474,  1.4641, -0.4858,  ...,  0.9375, -0.8243,  1.2091],\n",
      "         [ 0.1929,  0.6048, -0.1334,  ...,  1.3890,  0.0000,  1.4500],\n",
      "         ...,\n",
      "         [ 0.6477,  0.9868,  1.1105,  ...,  0.0000, -1.0993,  0.0000],\n",
      "         [-0.7061,  0.8304,  1.6773,  ..., -0.9172,  0.9238,  0.8761],\n",
      "         [-0.5044,  0.1624, -0.2503,  ...,  0.8147, -0.3450,  2.8257]],\n",
      "\n",
      "        [[-0.5434, -0.0085,  1.0218,  ...,  2.6486, -1.3499,  2.3083],\n",
      "         [-0.2925, -0.0539, -0.1110,  ...,  0.0000, -1.1553,  1.4289],\n",
      "         [ 0.0000, -0.1351, -0.9998,  ...,  0.9369,  2.1401, -0.6309],\n",
      "         ...,\n",
      "         [ 0.0000,  2.1577,  1.7328,  ...,  0.9757,  2.5260, -0.2278],\n",
      "         [-0.3027,  0.5821,  1.1046,  ...,  1.1602, -0.0000,  1.6554],\n",
      "         [ 1.0303,  1.6405,  1.4378,  ...,  1.2119,  0.2646,  0.9062]],\n",
      "\n",
      "        [[ 1.8954, -1.2147,  0.0554,  ..., -0.0139,  0.8222,  1.0978],\n",
      "         [ 0.2164, -1.0280, -0.8586,  ...,  0.0000, -1.2365,  3.1553],\n",
      "         [ 2.2128, -1.1757,  0.0000,  ...,  0.0000,  1.8513,  1.3509],\n",
      "         ...,\n",
      "         [ 0.3582,  0.4389,  0.0000,  ...,  3.7906,  0.0000,  3.4037],\n",
      "         [ 1.2078, -0.3160,  1.6456,  ...,  2.1602, -0.1795,  2.3262],\n",
      "         [ 0.8687, -0.5962,  0.0686,  ..., -0.0251,  1.1886,  2.2473]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.9302,  1.3974,  1.2693,  ...,  1.9158, -0.2768,  1.1206],\n",
      "         [ 2.0973,  2.1746, -0.9450,  ...,  2.0300, -1.7082,  1.5648],\n",
      "         [-0.0000,  0.0264, -0.4067,  ...,  1.1218, -1.1383,  2.0261],\n",
      "         ...,\n",
      "         [ 0.9173,  1.9689, -0.7557,  ..., -0.1207,  0.9215,  0.4002],\n",
      "         [-0.0000,  3.4960,  2.9485,  ...,  1.6557, -0.6356,  3.1632],\n",
      "         [-1.5087,  3.3361,  0.6084,  ...,  1.4271,  0.0319,  1.3951]],\n",
      "\n",
      "        [[ 0.8937, -1.1783,  2.0428,  ...,  1.3304, -0.0563, -0.2512],\n",
      "         [ 0.3767, -2.0605, -0.3709,  ..., -0.6451, -0.2126,  0.4804],\n",
      "         [ 0.0817,  1.7511,  2.7734,  ...,  2.6684,  0.4140, -0.4333],\n",
      "         ...,\n",
      "         [ 0.9927, -1.5848,  2.0760,  ...,  0.9503, -1.1970,  0.0000],\n",
      "         [ 0.0318, -0.2223, -0.9235,  ...,  0.4278, -0.0000,  1.1127],\n",
      "         [ 2.5215,  0.0563,  1.5134,  ...,  0.2941,  0.1175,  1.1844]],\n",
      "\n",
      "        [[-0.2663, -0.4449,  0.9814,  ...,  1.7046,  1.0093,  0.4001],\n",
      "         [ 0.4638,  0.8736,  0.9553,  ..., -0.8082,  1.1378, -0.6915],\n",
      "         [-0.2577,  0.2206,  0.2154,  ...,  0.0000, -1.2917,  1.4498],\n",
      "         ...,\n",
      "         [-0.7228, -2.1277,  1.4209,  ...,  1.6669, -0.3811,  0.7508],\n",
      "         [ 2.9107,  1.9156, -0.8463,  ...,  0.6742, -1.1765,  1.1344],\n",
      "         [-1.1765, -1.0014,  0.6094,  ...,  1.2600,  0.6678,  3.1495]]])\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/var/folders/23/hpkxkv9121b6yf_cr4hmvw900000gn/T/ipykernel_47477/3363211097.py:39\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m10\u001b[39m, \u001b[39m32\u001b[39m, \u001b[39m512\u001b[39m)\n\u001b[1;32m     38\u001b[0m encoder \u001b[39m=\u001b[39m Encoder(\u001b[39m512\u001b[39m, \u001b[39m1024\u001b[39m, \u001b[39m6\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m0.1\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m enc_output \u001b[39m=\u001b[39m encoder(\u001b[39minput\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Desktop/wip/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/var/folders/23/hpkxkv9121b6yf_cr4hmvw900000gn/T/ipykernel_47477/3363211097.py:13\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, src, mask)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, src, mask):\n\u001b[0;32m---> 13\u001b[0m     IPython\u001b[39m.\u001b[39;49membed()\n\u001b[1;32m     14\u001b[0m     src \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_encoder(src)\n\u001b[1;32m     15\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer_encoder(src, src_key_padding_mask\u001b[39m=\u001b[39mmask)\n",
      "File \u001b[0;32m~/Desktop/wip/venv/lib/python3.8/site-packages/IPython/terminal/embed.py:399\u001b[0m, in \u001b[0;36membed\u001b[0;34m(header, compile_flags, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m frame \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39m_getframe(\u001b[39m1\u001b[39m)\n\u001b[1;32m    397\u001b[0m shell \u001b[39m=\u001b[39m InteractiveShellEmbed\u001b[39m.\u001b[39minstance(_init_location_id\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (\n\u001b[1;32m    398\u001b[0m     frame\u001b[39m.\u001b[39mf_code\u001b[39m.\u001b[39mco_filename, frame\u001b[39m.\u001b[39mf_lineno), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 399\u001b[0m shell(header\u001b[39m=\u001b[39;49mheader, stack_depth\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, compile_flags\u001b[39m=\u001b[39;49mcompile_flags,\n\u001b[1;32m    400\u001b[0m     _call_location_id\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m%s\u001b[39;49;00m\u001b[39m:\u001b[39;49m\u001b[39m%s\u001b[39;49;00m\u001b[39m'\u001b[39;49m \u001b[39m%\u001b[39;49m (frame\u001b[39m.\u001b[39;49mf_code\u001b[39m.\u001b[39;49mco_filename, frame\u001b[39m.\u001b[39;49mf_lineno))\n\u001b[1;32m    401\u001b[0m InteractiveShellEmbed\u001b[39m.\u001b[39mclear_instance()\n\u001b[1;32m    402\u001b[0m \u001b[39m#restore previous instance\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/wip/venv/lib/python3.8/site-packages/IPython/terminal/embed.py:245\u001b[0m, in \u001b[0;36mInteractiveShellEmbed.__call__\u001b[0;34m(self, header, local_ns, module, dummy, stack_depth, compile_flags, **kw)\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshow_banner()\n\u001b[1;32m    243\u001b[0m \u001b[39m# Call the embedding code with a stack depth of 1 so it can skip over\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[39m# our call and get the original caller's namespaces.\u001b[39;00m\n\u001b[0;32m--> 245\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmainloop(\n\u001b[1;32m    246\u001b[0m     local_ns, module, stack_depth\u001b[39m=\u001b[39;49mstack_depth, compile_flags\u001b[39m=\u001b[39;49mcompile_flags\n\u001b[1;32m    247\u001b[0m )\n\u001b[1;32m    249\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbanner2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mold_banner2\n\u001b[1;32m    251\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexit_msg \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/wip/venv/lib/python3.8/site-packages/IPython/terminal/embed.py:337\u001b[0m, in \u001b[0;36mInteractiveShellEmbed.mainloop\u001b[0;34m(self, local_ns, module, stack_depth, compile_flags)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_completer_frame()\n\u001b[1;32m    336\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuiltin_trap, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdisplay_trap:\n\u001b[0;32m--> 337\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minteract()\n\u001b[1;32m    339\u001b[0m \u001b[39m# now, purge out the local namespace of IPython's hidden variables.\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[39mif\u001b[39;00m local_ns \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/wip/venv/lib/python3.8/site-packages/IPython/terminal/interactiveshell.py:670\u001b[0m, in \u001b[0;36mTerminalInteractiveShell.interact\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseparate_in, end\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    669\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 670\u001b[0m     code \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprompt_for_code()\n\u001b[1;32m    671\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mEOFError\u001b[39;00m:\n\u001b[1;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m (\u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfirm_exit) \\\n\u001b[1;32m    673\u001b[0m             \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mask_yes_no(\u001b[39m'\u001b[39m\u001b[39mDo you really want to exit ([y]/n)?\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mn\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/Desktop/wip/venv/lib/python3.8/site-packages/IPython/terminal/interactiveshell.py:429\u001b[0m, in \u001b[0;36mTerminalInteractiveShell.init_prompt_toolkit_cli.<locals>.prompt\u001b[0;34m()\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprompt\u001b[39m():\n\u001b[1;32m    428\u001b[0m     prompt_text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(x[\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprompts\u001b[39m.\u001b[39min_prompt_tokens())\n\u001b[0;32m--> 429\u001b[0m     lines \u001b[39m=\u001b[39m [\u001b[39minput\u001b[39;49m(prompt_text)]\n\u001b[1;32m    430\u001b[0m     prompt_continuation \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(x[\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprompts\u001b[39m.\u001b[39mcontinuation_prompt_tokens())\n\u001b[1;32m    431\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_complete(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(lines))[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mincomplete\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/wip/venv/lib/python3.8/site-packages/IPython/utils/py3compat.py:48\u001b[0m, in \u001b[0;36minput\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minput\u001b[39m(prompt\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m---> 48\u001b[0m     \u001b[39mreturn\u001b[39;00m builtin_mod\u001b[39m.\u001b[39;49minput(prompt)\n",
      "File \u001b[0;32m~/Desktop/wip/venv/lib/python3.8/site-packages/ipykernel/kernelbase.py:1177\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_allow_stdin:\n\u001b[1;32m   1174\u001b[0m     \u001b[39mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[1;32m   1175\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1176\u001b[0m     )\n\u001b[0;32m-> 1177\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_input_request(\n\u001b[1;32m   1178\u001b[0m     \u001b[39mstr\u001b[39;49m(prompt),\n\u001b[1;32m   1179\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parent_ident[\u001b[39m\"\u001b[39;49m\u001b[39mshell\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m   1180\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_parent(\u001b[39m\"\u001b[39;49m\u001b[39mshell\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1181\u001b[0m     password\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1182\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/wip/venv/lib/python3.8/site-packages/ipykernel/kernelbase.py:1219\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1216\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1218\u001b[0m     \u001b[39m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m-> 1219\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInterrupted by user\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m   1220\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1221\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog\u001b[39m.\u001b[39mwarning(\u001b[39m\"\u001b[39m\u001b[39mInvalid Message:\u001b[39m\u001b[39m\"\u001b[39m, exc_info\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# Encoder network\n",
    "# The encoder is any network that can take as input a variable-length sequence: so, RNNs, CNNs, and self-attention/Transformer encoders will all work.\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_heads, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.pos_encoder = PositionalEncoding(input_size)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=input_size, nhead=num_heads, dim_feedforward=hidden_size, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers, norm=nn.LayerNorm(input_size))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src, mask):\n",
    "        IPython.embed()\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, src_key_padding_mask=mask)\n",
    "        output = self.dropout(output)\n",
    "        return output\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "    \n",
    "# Testing output\n",
    "input = torch.randn(10, 32, 512)\n",
    "encoder = Encoder(512, 1024, 6, 8, 0.1)\n",
    "enc_output = encoder(input, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 32, 512])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictor network\n",
    "# The predictor is any causal network (= can't look at the future): in other words, unidirectional RNNs, causal convolutions, or masked self-attention.\n",
    "\n",
    "class MaskedSelfAttention(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_heads, dropout):\n",
    "        super(MaskedSelfAttention, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = nn.MultiheadAttention(input_size, num_heads, dropout)\n",
    "        self.layer_norm = nn.LayerNorm(input_size)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # x: (seq_len, batch_size, input_size)\n",
    "        x = x.transpose(0, 1) # (batch_size, seq_len, input_size)\n",
    "        self.attention_output, _ = self.attention(x, x, x, attn_mask=mask)\n",
    "        # attention_output: (batch_size, seq_len, input_size)\n",
    "        x = x + self.attention_output\n",
    "        x = self.layer_norm(x)\n",
    "        x = x.transpose(0, 1) # (seq_len, batch_size, input_size)\n",
    "        return x\n",
    "\n",
    "class PredictorNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_heads, dropout):\n",
    "        super(PredictorNetwork, self).__init__()\n",
    "        self.masked_self_attention_layers = nn.ModuleList([\n",
    "            MaskedSelfAttention(input_size, hidden_size, num_heads, dropout) for _ in range(num_layers)\n",
    "        ])\n",
    "        self.feedforward_layers = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(input_size, hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(hidden_size, input_size),\n",
    "                nn.Dropout(dropout),\n",
    "            ) for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        for attention_layer, feedforward_layer in zip(self.masked_self_attention_layers, self.feedforward_layers):\n",
    "            x = attention_layer(x, mask)\n",
    "            x = feedforward_layer(x)\n",
    "        return x\n",
    "    \n",
    "# Testing output with a mask\n",
    "input = torch.randn(10, 32, 512)\n",
    "predictor = PredictorNetwork(512, 1024, 6, 8, 0.1)\n",
    "\n",
    "mask = torch.zeros(32, 32)\n",
    "mask = torch.triu(mask, diagonal=1)\n",
    "mask = mask.bool()\n",
    "\n",
    "pred_output = predictor(input, mask)\n",
    "pred_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
